{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIErA93i0oVw",
    "outputId": "edf8fa2a-6878-4619-b4e9-b55abcfd1801",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TZ7j3Ls3RHU",
    "outputId": "50ce576b-8e7b-4bd5-880a-b9fe5a8fd16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: packaging in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: wrapt>=1.11.0 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in h:\\programs\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in h:\\programs\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in h:\\programs\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in h:\\programs\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in h:\\programs\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in h:\\programs\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in h:\\programs\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in h:\\programs\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in h:\\programs\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in h:\\programs\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in h:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in h:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in h:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in h:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in h:\\programs\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.12.6 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.11.0 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qJ-eyli3QE3",
    "outputId": "33c9c9af-f9ea-453c-ec29-4576afe76591"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlHl7d353tQZ",
    "outputId": "86e588ca-1100-40c7-e39d-b273f5ac5351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From H:\\programs\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import*\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdLJsdEg0oV0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Our Fixed Parameters\n",
    "\"\"\"\n",
    "TRAIN_DIR = 'Train';TEST_DIR = 'Test'\n",
    "IMG_SIZE =50;LR = 0.001\n",
    "MODEL_NAME = 'Sports-cnn';epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QieKmWT-0oV0"
   },
   "outputs": [],
   "source": [
    "def create_label(image_name):\n",
    "    \"\"\"\n",
    "        [1] Description: Encoded Each Class Between 0:5\n",
    "        [2] Arguments: image_name\n",
    "        [3] Return: numpy array of encoded value\n",
    "    \"\"\"\n",
    "    word_label = image_name.split('_')[0]\n",
    "    if word_label == 'Tennis':#4\n",
    "        return np.array([0,1,0,0,0,0])\n",
    "    elif word_label == 'Football':#1\n",
    "        return np.array([0,0,0,0,1,0])\n",
    "    elif word_label == 'Yoga':#5\n",
    "        return np.array([1,0,0,0,0,0])\n",
    "    elif word_label == 'Basketball':#0\n",
    "        return np.array([0,0,0,0,0,1])\n",
    "    elif word_label == 'Swimming':#3\n",
    "        return np.array([0,0,1,0,0,0])\n",
    "    elif word_label == 'Rowing':#2\n",
    "        return np.array([0,0,0,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI7g40aD0oV1"
   },
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    \"\"\"\n",
    "        [1] Description: Create Train Data (Value of Image,Label)\n",
    "        [2] Arguments: None\n",
    "        [3] Return: training_data (List)\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img_data = cv2.imread('data\\Train',0)\n",
    "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
    "        training_data.append([np.array(img_data), create_label(img)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3BqLkc_6sIS",
    "outputId": "6181271a-bfa6-44d3-ac4d-d2721cf7df66"
   },
   "outputs": [],
   "source": [
    "os.listdir(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWlxyT680oV2"
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "def create_test_data():\n",
    "    \"\"\"\n",
    "        [1] Description: Create Test Data (Value of Image,Label)\n",
    "        [2] Arguments: None\n",
    "        [3] Return: testing_data (List)\n",
    "    \"\"\"\n",
    "    testing_data=[]\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img_data = cv2.imread('data\\Test', 0)\n",
    "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append(np.array(img_data))\n",
    "        labels.append(img)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEDTNTvb0oV3",
    "outputId": "50b15c43-228b-43b6-eca6-5e60bdadc0df"
   },
   "outputs": [],
   "source": [
    "'''if (os.path.exists('/content/train_data.npy')): # If you have already created the dataset:\n",
    "    train_data =np.load(r'/content/train_data.npy', allow_pickle=True)\n",
    "    #train_data = create_train_data()\n",
    "else: # If dataset is not created:'''\n",
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "reZ2F9oQ0oV4",
    "outputId": "3858bada-72db-4e5c-ffa1-12e4fbd20347"
   },
   "outputs": [],
   "source": [
    "'''if (os.path.exists(r'/content/test_data.npy')):\n",
    "    test_data =np.load(r'/content/test_data.npy',allow_pickle=True)\n",
    "else:'''\n",
    "test_data = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mswwrobt0oV5"
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1H4ybwz6nRL",
    "outputId": "fcfa209f-efa9-4b65-f696-5a26b30565bf"
   },
   "outputs": [],
   "source": [
    "train[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khne7hMl6aIr"
   },
   "outputs": [],
   "source": [
    "train[0]=train[0]/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVxrtKzl4dIe"
   },
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(train[0],train[1], test_size=0.20,shuffle=True)\n",
    "X_tr = np.array([i for i in X_tr]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y_tr = [i for i in y_tr]\n",
    "X_te = np.array([i for i in X_te]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y_te = [i for i in y_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "Czr-msPXvWpi",
    "outputId": "a54f45ca-463a-4006-8dfe-8b6f6f0a9714"
   },
   "outputs": [],
   "source": [
    "class_names = ['Basketball', 'Yoga', 'Football', 'Swimming', 'Rowing',\n",
    "               'Tennis']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIhfhSk-0oV6",
    "outputId": "6d243e53-1b8b-4246-86ad-39aa6976a978"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "conv_input = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "conv1 = conv_2d(conv_input, 64, 2, activation='relu')\n",
    "pool1 = max_pool_2d(conv1, 3)\n",
    "\n",
    "\n",
    "fully_layer = fully_connected(pool1, 512, activation='relu')\n",
    "fully_layer = dropout(fully_layer, 0.3)\n",
    "\n",
    "cnn_layers = fully_connected(fully_layer, 6, activation='softmax')\n",
    "\n",
    "\n",
    "cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "model = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)\n",
    "'''if (os.path.exists('model.tfl.meta')):\n",
    "    model.load('./model.tfl')\n",
    "else:'''\n",
    "m=model.fit({'input': X_tr}, {'targets': y_tr}, \n",
    "               validation_set=({'input': X_te}, {'targets': y_te})\n",
    "              , n_epoch=epochs,snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "model.save('model.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D57DkO4M0oV6"
   },
   "outputs": [],
   "source": [
    "FINAL_TEST_X = np.array([i for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUpH5Sk_-7Qe"
   },
   "outputs": [],
   "source": [
    "TEST_Y = model.predict(FINAL_TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8wP9PFnPd0x",
    "outputId": "61b9b5ab-e919-4866-b92e-e4d7429848cd"
   },
   "outputs": [],
   "source": [
    "TEST_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BYL99qq_CBd"
   },
   "outputs": [],
   "source": [
    "FINAL_TEST_Y = []\n",
    "for i in TEST_Y:\n",
    "  max = -99999\n",
    "  i=i[::-1]\n",
    "  for d in range(0,len(i)):\n",
    "    if i[d] > max:\n",
    "        max = i[d]\n",
    "        index = d\n",
    "  FINAL_TEST_Y.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wKvmB7gL_Gbp",
    "outputId": "b5dc7ec2-0309-4b9f-feda-509572d0f17f"
   },
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "final[\"image\"] =  labels\n",
    "final[\"label\"] = FINAL_TEST_Y\n",
    "final.join(pd.DataFrame(TEST_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StTdtVo5X7ZV"
   },
   "outputs": [],
   "source": [
    "final.to_csv('Final.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d52e466cda7d84e374c198ef38904e0acd3c372c025224e78ff0d3f2eb7b76d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
